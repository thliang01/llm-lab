{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df8ae2d-0c56-48f2-bef6-d7798800bfd5",
   "metadata": {},
   "source": [
    "# 01 - å°è©±è³‡æ–™ç”Ÿæˆ & å°è©±é›†æ ¼å¼ä»‹ç´¹\n",
    "<div align=\"left\" style=\"line-height: 1;\">\n",
    "  <a href=\"https://discord.gg/Cx737yw4ed\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-Twinkle%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "  <a href=\"https://huggingface.co/twinkle-ai\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Twinkle%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "      <a href=\"https://colab.research.google.com/github/ai-twinkle/llm-lab/blob/main/courses/2025-08-llm-dialogue-dataset/01_generate_dialogs.ipynb\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open 01_generate_dialogs In Colab\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "</div>\n",
    "\n",
    "åœ¨é€™å€‹ Labï¼Œæˆ‘å€‘çš„ç›®æ¨™æ˜¯å»ºç«‹ä¸€ä»½ã€Œå¯æŒçºŒæ“´å……ã€çš„å°è©±è³‡æ–™é›†ã€‚ä¸»è¦çš„æ­¥é©Ÿå¦‚ä¸‹ï¼š\n",
    "1. é‡é€£ `Gemma-3-12B-it` APIï¼ˆä½¿ç”¨ OpenAI SDKï¼‰\n",
    "2. ä»‹ç´¹å°è©±è³‡æ–™çš„å¸¸è¦‹æ ¼å¼ï¼š**Alpaca**, **ShareGPT**ï¼Œä»¥åŠ **OpenAI** æ ¼å¼ï¼ˆæˆ‘å€‘æ¡ç”¨å¾Œè€…ï¼‰\n",
    "3. æ¢è¨ `.jsonl` æ ¼å¼èˆ‡ `.parquet` æ ¼å¼çš„å„ªç¼ºé»ï¼Œä¸¦èªªæ˜ HF Hub å° parquet çš„è½‰æ›æ”¯æ´\n",
    "   (ä¸Šå‚³ parquet æ™‚ HF æœƒè‡ªå‹•ç”Ÿæˆ `.parquet` åˆ†æ”¯èˆ‡ viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9f103-b0f0-468b-ba19-ca0b4556e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# é‡æ–°åˆå§‹åŒ– API client\n",
    "API_KEY = \"\"  # å‘ Twinkle AI ç¤¾ç¾¤ç´¢å–\n",
    "BASE_URL = \"https://litellm-ekkks8gsocw.dgx-coolify.apmic.ai\"\n",
    "MODEL = \"gemma-3-12b-it\"\n",
    "client = OpenAI(api_key=API_KEY, base_url=f\"{BASE_URL}/v1\")\n",
    "print(\"API client å·²åˆå§‹åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa29ba-2e60-4041-a21f-c8f328f61304",
   "metadata": {},
   "source": [
    "## å¸¸è¦‹å°è©±è³‡æ–™é›†æ ¼å¼æ¯”è¼ƒ\n",
    "\n",
    "- **Alpaca**ï¼šå–®è¼ªæŒ‡ä»¤ + å›ç­”æ ¼å¼ï¼Œé€šå¸¸æ˜¯ Instruct tuningã€‚ï¼ˆä¸é©åˆå¤šè¼ªå ´æ™¯ï¼‰\n",
    "- **ShareGPT**ï¼šä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼Œæ”¯æ´å¤šè§’è‰²å¤šè¼ªå°è©±\n",
    "```json\n",
    "{\n",
    "    \"conversations\":[\n",
    "        {\"from\":\"human\",\"value\":\"...\"},\n",
    "        {\"from\":\"gpt\",\"value\":\"...\"}â€¦]\n",
    "}\n",
    "```\n",
    "- **OpenAI Chat Messages**ï¼šæœ€å¸¸ç”¨æ ¼å¼ï¼Œåƒé€™æ¨£ï¼š\n",
    "```json\n",
    "{\n",
    "  \"messages\":[\n",
    "      {\"role\":\"system\",\"content\":\"...\"},\n",
    "      {\"role\":\"user\",\"content\":\"...\"},\n",
    "      {\"role\":\"assistant\",\"content\":\"...\"}]\n",
    "}\n",
    "```\n",
    "Hugging Face èˆ‡å¤šæ•¸å·¥å…·éƒ½æ”¯æ´é€™ç¨®æ ¼å¼ï¼Œä¸” OpenAI æœ¬è³ªä¸Šæ˜¯ ShareGPT æ ¼å¼çš„è®Šé«”  ï¿¼\n",
    "\n",
    "æˆ‘å€‘å°‡æ¡ç”¨ **OpenAI messages** æ ¼å¼ï¼Œä¸¦ä½¿ç”¨ `.jsonl` å„²å­˜ï¼›å¦å¤–ï¼Œé‚„æœ‰ä¸€ç¨®å« `.parquet` æ ¼å¼ï¼Œä»–çš„å„ªå‹¢ä¾‹å¦‚ï¼š\n",
    "- é«˜æ•ˆå£“ç¸®ã€æ”¯æ´åˆ†æ¬„è®€å–ã€å¤§æª”æ¡ˆæ“ä½œå¿«é€Ÿ\n",
    "- HF Hub æ”¯æ´ç›´æ¥ä¸Šå‚³ parquetï¼Œä¹Ÿæœƒè‡ªå‹•ç”Ÿæˆå¯å…¬é–‹ç€è¦½ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241fddab-ede4-4d95-86b7-569bee685087",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"assets/01_wiki_data_format.png\" width=\"100%\"/><br/>\n",
    "  <em align=\"center\">åœ– 1ï¼šWiki å°è©±æ ¼å¼ç¤ºæ„åœ–</em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd084c2b-1741-4a4d-8932-5e6dfdfafcfa",
   "metadata": {},
   "source": [
    "## JSONL vs Parquet æ¯”è¼ƒ\n",
    "\n",
    "| æ ¼å¼     | å„ªé»                          | ç¼ºé»                         |\n",
    "|----------|-------------------------------|------------------------------|\n",
    "| `.jsonl` | æ˜“è®€ã€è¼•é‡ã€é–‹ç™¼å‹å–„              | æª”æ¡ˆå¤§ã€å¤§é‡æ•¸æ“šè®€å–æ•ˆç‡è¼ƒä½   |\n",
    "| `.parquet` | å£“ç¸®æ•ˆæœå¥½ã€æŸ¥è©¢æ•ˆèƒ½é«˜ã€æ”¯æ´ HF è½‰æ› | ä¸æ˜“ç›´æ¥é–±è®€ï¼Œéœ€ä½¿ç”¨å·¥å…·è™•ç†   |\n",
    "\n",
    "æ³¨æ„ï¼šå³ä½¿ä½ ä¸Šå‚³ `.jsonl`ï¼ŒHF Hub ä¹Ÿå¯èƒ½å¹«ä½ ç”Ÿæˆ `.parquet` åˆ†æ”¯ï¼Œæ–¹ä¾¿ç€è¦½èˆ‡è¼‰å…¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a123e6-20c2-41d3-a235-7cfc8974c969",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"assets/01_hf_parquet_branch.png\" width=\"100%\"/><br/>\n",
    "  <em>åœ– 2ï¼šHF Hub è‡ªå‹•ç”Ÿæˆçš„ .parquet åˆ†æ”¯</em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911efc9a-b8b9-4b28-92d8-c6d405ce31e3",
   "metadata": {},
   "source": [
    "## Reference-Free vs Reference-Based\n",
    "\n",
    "- **Reference-Freeï¼ˆç„¡åƒè€ƒï¼‰**ï¼šç”¨ä¸€äº› seed prompt å¼•å°æ¨¡å‹ç”Ÿæˆã€‚æœ€æ—©å‡ºè‡ª [Self-Instruct: Aligning Language Models with Self-Generated Instructions\n",
    "](https://arxiv.org/abs/2212.10560)ã€‚\n",
    "- **Reference-Basedï¼ˆåƒè€ƒå…§å®¹ï¼‰**ï¼šä½¿ç”¨çœŸå¯¦è³‡æ–™ç‰‡æ®µï¼ˆä¾‹å¦‚ Wiki æ¢ç›®ï¼‰ä½œ prompt ä½æ–™ï¼Œè®“ç”Ÿæˆå…§å®¹æ›´ groundedã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b3052-568d-4ab3-aa56-cc5fe2c942ab",
   "metadata": {},
   "source": [
    "### Reference-Free å¯¦ä½œ\n",
    "\n",
    "åœ¨ Reference-Free çš„æƒ…å¢ƒä¸‹ï¼Œæˆ‘å€‘ä¸¦ä¸ä¾è³´ä»»ä½•å¤–éƒ¨çŸ¥è­˜åº«æˆ–æ–‡ä»¶ï¼Œè€Œæ˜¯é€é **seed ä»»å‹™ (seed task)** ä¾†é©…å‹•æ¨¡å‹è‡ªè¡Œç”Ÿæˆè³‡æ–™ã€‚  \n",
    "é€™äº› seed ä»»å‹™é€šå¸¸åŒ…å«ä¸€å€‹ **instructionï¼ˆæŒ‡ä»¤ï¼‰**ï¼ŒåŠ ä¸Šå°‘é‡çš„ **instanceï¼ˆç¯„ä¾‹è¼¸å…¥/è¼¸å‡ºå°ï¼‰**ï¼Œä½œç‚ºæ¨¡å‹æ¨¡ä»¿èˆ‡å»¶ä¼¸çš„èµ·é»ã€‚  \n",
    "\n",
    "é€™ç¨®æ–¹æ³•çš„ä»£è¡¨æ€§å·¥ä½œæ˜¯ *Self-Instruct*ï¼Œå®ƒé€éäººå·¥è¨­è¨ˆçš„ä¸€äº›é«˜å“è³ªç¨®å­æŒ‡ä»¤ï¼Œè®“æ¨¡å‹å»ã€Œèˆ‰ä¸€åä¸‰ã€ç”¢ç”Ÿæ›´å¤šæŒ‡ä»¤å’Œå°æ‡‰ç­”æ¡ˆï¼Œæœ€çµ‚å»ºç«‹å‡ºé¾å¤§çš„è³‡æ–™é›†ã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ä¸€å€‹å–è‡ª [self-instruct](https://github.com/yizhongw/self-instruct/blob/main/data/seed_tasks.jsonl) seed ç¯„ä¾‹ï¼Œä¸»é¡Œæ˜¯ã€Œæ—©é¤å»ºè­°ã€ã€‚  \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"seed_task_0\",\n",
    "  \"name\": \"breakfast_suggestion\",\n",
    "  \"instruction\": \"Is there anything I can eat for a breakfast that doesn't include eggs, yet includes protein, and has roughly 700-1000 calories?\",\n",
    "  \"instances\": [\n",
    "    {\n",
    "      \"input\": \"\",\n",
    "      \"output\": \"Yes, you can have 1 oatmeal banana protein shake and 4 strips of bacon. The oatmeal banana protein shake may contain 1/2 cup oatmeal, 60 grams whey protein powder, 1/2 medium banana, 1 tbsp flaxseed oil and 1/2 cup water, totaling about 550 calories. The 4 strips of bacon contains about 200 calories.\"\n",
    "    }\n",
    "  ],\n",
    "  \"is_classification\": false\n",
    "}\n",
    "```\n",
    "èªªæ˜ï¼š\n",
    "- idï¼šä»»å‹™çš„å”¯ä¸€è­˜åˆ¥ç¢¼ã€‚\n",
    "- nameï¼šä»»å‹™åç¨±ï¼Œæ–¹ä¾¿è¾¨è­˜ã€‚\n",
    "- instructionï¼šçµ¦æ¨¡å‹çš„ä¸»è¦å•é¡Œæˆ–æŒ‡ä»¤ã€‚\n",
    "- instancesï¼šåŒ…å«è¼¸å…¥/è¼¸å‡ºå°ï¼Œæœ¬ä¾‹ä¸­ input ç‚ºç©ºï¼Œä»£è¡¨æ¨¡å‹ç›´æ¥ä¾ instruction å›ç­”ï¼›output æ˜¯ä¸€å€‹å¯èƒ½çš„è§£ç­”ã€‚\n",
    "- is_classificationï¼šæ¨™è¨˜æ­¤ä»»å‹™æ˜¯å¦ç‚ºåˆ†é¡å‹å•é¡Œï¼ˆæ­¤ä¾‹ç‚ºå¦ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52128cae-647b-43da-913d-04aed64fc783",
   "metadata": {},
   "source": [
    "åœ¨å¯¦å‹™ä¸­ï¼Œæˆ‘å€‘æœƒè¨­è¨ˆæ•¸ååˆ°æ•¸ç™¾å€‹ seed ä»»å‹™ï¼Œæ¶µè“‹ä¸åŒé ˜åŸŸèˆ‡æŒ‡ä»¤å‹æ…‹ï¼Œä½œç‚º Reference-Free è³‡æ–™ç”Ÿæˆçš„æ ¸å¿ƒåŸºç¤ã€‚\n",
    "\n",
    "ä¸éï¼Œæˆ‘å€‘çš„ä½œæ³•ä¸¦**ä¸å®Œå…¨ç­‰åŒæ–¼ Self-Instruct**ã€‚\n",
    "ç›¸è¼ƒæ–¼ Self-Instruct çš„å®Œæ•´ pipelineï¼ˆå¦‚ï¼šéæ¿¾ã€å»é‡ã€è¿­ä»£æ“´å±•ï¼‰ï¼Œæˆ‘å€‘å‚¾å‘æ¡ç”¨æ›´ç°¡å–®ç›´æ¥çš„æ–¹å¼ï¼š\n",
    "\t1.\täººå·¥æ’°å¯«å°‘é‡é«˜å“è³ª seed æŒ‡ä»¤ã€‚\n",
    "\t2.\tè¦æ±‚æ¨¡å‹åŸºæ–¼é€™äº› seed ç”¢ç”Ÿæ–°çš„ seed æŒ‡ä»¤ï¼ˆä½†åƒ…é™è¼¸å‡º seed æœ¬æ–‡ï¼Œé¿å…é›œè¨Šï¼‰ã€‚\n",
    "\t3.\tå†åˆ©ç”¨é€™äº›æ–° seed æŒ‡ä»¤ï¼Œç”±æ¨¡å‹ç”Ÿæˆå–®è¼ªå•ç­”é…å°ã€‚\n",
    "\n",
    "é€™æ¨£çš„æµç¨‹æ›´è¼•é‡ï¼Œé›–ç„¶ç¼ºå°‘è¤‡é›œçš„ç¯©é¸èˆ‡å¤šè¼ªè¿­ä»£ï¼Œä½†å°æ–¼èª²ç¨‹å¯¦ä½œèˆ‡æ•™å­¸ç›®æ¨™è€Œè¨€ï¼Œå·²ç¶“èƒ½æ¸…æ¥šå±•ç¾ Reference-Free çš„æ ¸å¿ƒç²¾ç¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cbf67-aca6-4e63-854f-d08a889ea711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: ä»¥æ—¢æœ‰ seed ç‚ºå‡ºç™¼é»ï¼Œè¦æ±‚ LLM ç”¢ç”Ÿã€Œä¸åŒä½†ç›¸é—œã€çš„æ–° seedã€‚\n",
    "# é‡è¦ï¼šåš´æ ¼è¦æ±‚åªè¼¸å‡º seed æ–‡å­—æœ¬èº«ï¼Œä¸è¦ä»»ä½•å¤šé¤˜èªªæ˜ã€æ¨™ç±¤æˆ–å¼•è™Ÿã€‚\n",
    "\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "# å‡è¨­ä½ å·²ç¶“åœ¨å‰é¢åˆå§‹åŒ–é client / MODEL\n",
    "# client = OpenAI(api_key=API_KEY, base_url=f\"{BASE_URL}/v1\")\n",
    "# MODEL = \"gemma-3-12b-it\"\n",
    "\n",
    "base_seed = \"Is there anything I can eat for a breakfast that doesn't include eggs, yet includes protein, and has roughly 700-1000 calories?\"\n",
    "\n",
    "seed_gen_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"ä½ æ˜¯ä¸€å€‹è³‡æ–™ç”Ÿæˆå™¨ã€‚ä½ çš„ä»»å‹™æ˜¯ã€æ ¹æ“šçµ¦å®š seedï¼Œç”¢ç”Ÿä¸€å‰‡ä¸åŒä½†ä¸»é¡Œç›¸é—œçš„ seed æŒ‡ä»¤ã€ã€‚\\n\"\n",
    "            \"å‹™å¿…éµå®ˆï¼š\\n\"\n",
    "            \"1) åƒ…è¼¸å‡ºæ–°çš„ seed æŒ‡ä»¤æœ¬èº«ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚\\n\"\n",
    "            \"2) ä¸è¦åŠ ä»»ä½•è§£é‡‹ã€å‰å¾Œæ–‡ã€å¼•è™Ÿã€æ¨™é»è£é£¾æˆ–æ¨™ç±¤ã€‚\\n\"\n",
    "            \"3) ä¸€è‡³å…©å¥è©±ï¼Œæ¸…æ¥šå¯åŸ·è¡Œã€‚\\n\"\n",
    "            \"4) é¿å…é‡è¤‡èˆ‡åŸ seed å®Œå…¨ç›¸åŒçš„é™åˆ¶æ¢ä»¶æˆ–æªè¾­ï¼Œä½†ä¸»é¡Œéœ€ç›¸é—œã€‚\\n\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"é€™æ˜¯åŸå§‹ seedï¼š\\n{base_seed}\\n\\n\"\n",
    "            \"è«‹ä¾è¦å‰‡ç”¢ç”Ÿä¸€å€‹æ–°çš„ seed æŒ‡ä»¤ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚åªè¼¸å‡ºæ–° seed æœ¬æ–‡ï¼Œå…¶ä»–ä¸€å¾‹ä¸è¦ã€‚\"\n",
    "        )\n",
    "    },\n",
    "]\n",
    "\n",
    "resp_seed = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=seed_gen_messages,\n",
    "    temperature=0.9,\n",
    "    max_tokens=200,\n",
    ")\n",
    "\n",
    "new_seed_instruction_raw = resp_seed.choices[0].message.content.strip()\n",
    "\n",
    "# åŸºæœ¬æ¸…ç†ï¼šç§»é™¤å¸¸è¦‹å¤šé¤˜å­—æ¨£ï¼ˆä¿éšªï¼‰\n",
    "def sanitize_seed(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    # ç§»é™¤å¯èƒ½çš„ç¨‹å¼ç¢¼åœæ¬„æˆ–å¼•è™Ÿ\n",
    "    text = re.sub(r\"^```.*?\\n|\\n```$\", \"\", text, flags=re.DOTALL)  # å»æ‰ ``` å€å¡Š\n",
    "    text = text.strip(\"ã€Œã€\\\"'` \\n\\t\")\n",
    "    # å»æ‰å¯èƒ½çš„å‰ç¶´\n",
    "    text = re.sub(r\"^(æ–°çš„?seedæŒ‡ä»¤[:ï¼š]\\s*|seed[:ï¼š]\\s*|æ–°æŒ‡ä»¤[:ï¼š]\\s*)\", \"\", text, flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "new_seed_instruction = sanitize_seed(new_seed_instruction_raw)\n",
    "\n",
    "print(\"ğŸ”¹ åŸå§‹ seedï¼š\", base_seed)\n",
    "print(\"ğŸ”¸ æ–°çš„ seedï¼š\", new_seed_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef39f8-4d25-4404-bcc4-59c4da85a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: ä»¥ã€Œæ–°çš„ seed æŒ‡ä»¤ã€ç•¶ä½œ user æå•ï¼Œç”Ÿæˆå–®è¼ªå›ç­”ï¼ˆassistant ä¸€æ¬¡å›è¦†ï¼‰ã€‚\n",
    "# ç”¢å‡ºç‚º OpenAI messages æ ¼å¼ï¼Œå¯ç›´æ¥ç´¯ç©é€² datasets.jsonlã€‚\n",
    "\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from pathlib import Path\n",
    "\n",
    "qa_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½ç‡Ÿé¤Šèˆ‡é£²é£Ÿè¦åŠƒçš„å°ˆå®¶ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œçµ¦å‡ºæ˜ç¢ºã€å¯åŸ·è¡Œçš„å»ºè­°ã€‚\"},\n",
    "    {\"role\": \"user\", \"content\": new_seed_instruction},\n",
    "]\n",
    "\n",
    "resp_qa = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=qa_messages,\n",
    "    temperature=0.7,\n",
    "    max_tokens=600,\n",
    ")\n",
    "\n",
    "answer = resp_qa.choices[0].message.content\n",
    "\n",
    "example = {\n",
    "    \"id\": str(uuid4()),\n",
    "    \"type\": \"reference_free\",\n",
    "    \"messages\": [\n",
    "        qa_messages[0],                 # system\n",
    "        qa_messages[1],                 # userï¼ˆæ–°çš„ seedï¼‰\n",
    "        {\"role\": \"assistant\", \"content\": answer},  # å–®è¼ªå›ç­”\n",
    "    ]\n",
    "}\n",
    "\n",
    "# âœ… å¯é¸ï¼šè¿½åŠ å¯«å…¥ datasets.jsonlï¼ˆä¾›ä¸‹ä¸€ç« ç¯€ QC ä½¿ç”¨ï¼‰\n",
    "out_path = Path(\"outputs/datasets.jsonl\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with out_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"âœ… å·²ç”Ÿæˆå–®è¼ª QA ä¸¦å¯«å…¥ï¼š\", out_path)\n",
    "print(\"\\n=== å›ç­”é è¦½ ===\\n\", answer[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc5f17-dc9f-400b-9a1b-94f7975ac569",
   "metadata": {},
   "source": [
    "## Reference-based è³‡æ–™ç”Ÿæˆ\n",
    "\n",
    "åœ¨ Reference-based çš„æƒ…å¢ƒä¸‹ï¼Œæˆ‘å€‘æœƒä½¿ç”¨ä¸€æ®µå¤–éƒ¨æ–‡æœ¬ä½œç‚ºä¾æ“šï¼Œä¸¦åœ¨å…¶ä¸Šç”Ÿæˆå•ç­”è³‡æ–™ã€‚\n",
    "é€™ç¨®æ–¹å¼å¸¸è¦‹æ–¼çŸ¥è­˜å‹ QA ç³»çµ±ï¼ˆä¾‹å¦‚ Wikipedia å•ç­”ï¼‰ï¼Œå…¶æ ¸å¿ƒåŸå‰‡æ˜¯ï¼š\n",
    "- å•é¡Œï¼ˆQuestionï¼‰å¿…é ˆä¾†è‡ªæ–¼æ–‡æœ¬\n",
    "- ç­”æ¡ˆï¼ˆAnswerï¼‰å¿…é ˆå®Œå…¨ä¾ç…§æ–‡æœ¬ï¼Œä¸å¯è¶…å‡ºæ–‡æœ¬ç¯„åœ\n",
    "\n",
    "é€™æ¨£ç”Ÿæˆçš„è³‡æ–™ï¼Œå¯ä»¥å¹«åŠ©æ¨¡å‹å­¸æœƒã€Œæ ¹æ“šåƒè€ƒå…§å®¹å›ç­”ã€ï¼Œè€Œéæ†‘ç©ºæƒ³åƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7718b73-b95d-4a72-87af-530237830887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æˆ‘å€‘é€™è£¡ç›´æ¥ç¤ºç¯„ä¸€æ®µ Wikipedia ä¸­æ–‡æ¢ç›®ï¼ˆå–è‡ªå…¬é–‹è³‡æ–™é›† https://huggingface.co/datasets/lianghsun/wikipedia-zh-742Mï¼‰\n",
    "wiki_context = \"\"\"\n",
    "ä¸­è¯æ°‘åœ‹æ˜¯ä½æ–¼æ±äºçš„æ°‘ä¸»å…±å’Œåœ‹ï¼Œæ›¾åœ¨åœ‹éš›ä¸Šå»£æ³›ä»£è¡¨ã€Œä¸­åœ‹ã€ï¼Œç¾ä»Šå¤šé€šç¨±ç‚ºã€Œè‡ºç£ã€ï¼›\n",
    "ç›®å‰æœ‰æ•ˆç®¡è½„ç¯„åœåŒ…æ‹¬è‡ºç£ã€æ¾æ¹–ç¾¤å³¶åŠå…¶é™„å±¬å³¶å¶¼ï¼Œä»¥åŠä¸­åœ‹å¤§é™¸ç¦å»ºæ²¿å²¸çš„é‡‘é–€ç¾¤å³¶ã€é¦¬ç¥–åˆ—å³¶ç­‰å³¶å¶¼ï¼Œ\n",
    "å¤šåˆç¨±ç‚ºã€Œè‡ºæ¾é‡‘é¦¬ã€ï¼›åœŸåœ°é¢ç©å…±36,197å¹³æ–¹å…¬é‡Œï¼Œå…¶ä¸­è‡ºç£åŠå…¶é™„å±¬å³¶å¶¼ä½”99%ä»¥ä¸Šã€‚\n",
    "ç›®å‰ä»¥ä½å±…æ±äºå³¶å¼§çš„è‡ºç£æœ¬å³¶ç‚ºä¸»è¦é ˜åœŸï¼Œæ±è‡¨å¤ªå¹³æ´‹ã€è¥¿éš”è‡ºç£æµ·å³½ã€å—ç•Œå·´å£«æµ·å³½ã€åŒ—ç€•æ±æµ·ï¼Œ\n",
    "å…¶åœ°å½¢é™¡å³­ã€æ™¯è§€å¤šæ¨£ã€‚åœ‹åœŸç´„ä¸‰åˆ†ä¹‹äºŒçš„é¢ç©ç‚ºå±±åœ°å’Œä¸˜é™µåœ°å½¢ï¼Œå¤§éƒ¨åˆ†äººå£å‰‡å±…ä½æ–¼è‡ºç£è¥¿éƒ¨çš„å¹³åœ°ã€‚\n",
    "å…¨åœ‹äººå£ç´„2,300è¬äººï¼Œäººå£å¯†åº¦åœ¨å…¨ä¸–ç•Œäººå£å¤§æ–¼1,000è¬äººçš„åœ‹å®¶ä¸­ä½åˆ—ç¬¬äºŒã€‚\n",
    "é¦–éƒ½ç‚ºè‡ºåŒ—å¸‚ï¼Œäººå£æœ€å¤šçš„åŸå¸‚å‰‡ç‚ºæ–°åŒ—å¸‚ã€‚\n",
    "\"\"\"\n",
    "NUM_QA = 4  # æƒ³ç”¢ç”Ÿå¹¾çµ„ QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dab6b-5a35-4ef2-9cd5-638988ee81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ç”¢ç”Ÿã€Œåªæœ‰å•é¡Œã€â†’ å†é€é¡Œå›ç­”ï¼ˆReference-basedï¼‰====\n",
    "import json, re\n",
    "from typing import List\n",
    "from uuid import uuid4\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- (A) ç”¨ Structured Outputs ç”¢ç”Ÿã€Œå•é¡Œæ¸…å–®ã€ ----------\n",
    "# åƒè€ƒï¼šOpenAI Structured Outputs / responses.parseï¼ˆè‹¥ç«¯é»ä¸æ”¯æ´ï¼Œæœƒè‡ªå‹• fallbackï¼‰ \n",
    "# Docs: platform.openai.com/docs/guides/structured-outputs & responses.parse\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "\n",
    "class QuestionItem(BaseModel):\n",
    "    question: str = Field(..., min_length=4, description=\"ä¾æ“šçµ¦å®šæ–‡æœ¬å¯ç›´æ¥å›ç­”çš„å•é¡Œï¼ˆç¹é«”ä¸­æ–‡ï¼‰\")\n",
    "\n",
    "class QuestionList(BaseModel):\n",
    "    items: List[QuestionItem]\n",
    "\n",
    "def generate_questions_from_context(context: str, n_pairs: int = 4) -> List[str]:\n",
    "    sys_rules = (\n",
    "        \"ä½ æ˜¯è³‡æ–™æ¨™è¨»åŠ©ç†ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡è¨­è¨ˆå•é¡Œã€‚\\n\"\n",
    "        f\"è«‹ç”¢ç”Ÿ {n_pairs} é¡Œå•é¡Œï¼Œä¸è¦æä¾›ç­”æ¡ˆã€‚\\n\"\n",
    "        \"åŸå‰‡ï¼š\\n\"\n",
    "        \"1) å•é¡Œå¿…é ˆå¯ç”±ã€æ–‡æœ¬ã€‘ç›´æ¥å›ç­”ï¼Œæˆ–èƒ½å¿ å¯¦æ”¹å¯«è‡ªå…¶ä¸­è³‡è¨Šã€‚\\n\"\n",
    "        \"2) ç¦æ­¢åŠ å…¥ã€æ–‡æœ¬ã€‘ä»¥å¤–çš„çŸ¥è­˜ã€‚\\n\"\n",
    "        \"3) å•é¡Œè¦æ¸…æ¥šã€å…·é«”ï¼Œç­”æ¡ˆå¯åœ¨ 1â€“2 å¥å…§è¡¨é”ã€‚\\n\"\n",
    "        \"4) è‹¥ã€æ–‡æœ¬ã€‘ä¸è¶³ä»¥æ”¯æ’å•é¡Œï¼Œè«‹ç”¢ç”Ÿéœ€è¦ä½¿ç”¨è€…é€²ä¸€æ­¥é‡æ¸…çš„å•é¡Œï¼ˆå–®ä¸€å¥ï¼‰ã€‚\\n\"\n",
    "        \"5) å•é¡Œè¦è‡ªç„¶ï¼Œä¸è¦æš´éœ²æœ‰ä»»ä½•ã€æ–‡æœ¬ã€‘æˆ–å¤–éƒ¨è³‡æ–™å­˜åœ¨ã€‚\\n\"\n",
    "        \"6) åªè¼¸å‡º JSONï¼Œæ ¼å¼å›ºå®šç‚ºï¼š{\\\"items\\\":[{\\\"question\\\":\\\"...\\\"}, ...]}ã€‚\"\n",
    "    )\n",
    "    user_rules = (\n",
    "        \"è«‹æ ¹æ“šä»¥ä¸‹ã€æ–‡æœ¬ã€‘è¨­è¨ˆå•é¡Œï¼š\\n\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        \"âš ï¸ åƒ…è¼¸å‡º JSONï¼Œæ ¼å¼ï¼š{\\\"items\\\":[{\\\"question\\\":\\\"...\\\"}, ...]}ï¼Œ\"\n",
    "        \"ä¸å¾—æœ‰é¡å¤–èªªæ˜/Markdown/å‰å¾Œç¶´ã€‚\"\n",
    "    )\n",
    "\n",
    "    # ---- è·¯å¾‘ 1ï¼šresponses.parseï¼ˆæ”¯æ´æ™‚æœ€ç©©å®šï¼‰----\n",
    "    try:\n",
    "        parsed = client.beta.chat.completions.parse(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": sys_rules},\n",
    "                   {\"role\": \"user\", \"content\": user_rules}],\n",
    "            response_format=QuestionList,   # æ³¨æ„ï¼šé€™è£¡æ˜¯ä¸€å€‹ Pydantic Model class\n",
    "        )\n",
    "        # å–å¾—çµæ§‹åŒ–çµæœï¼ˆé—œéµï¼‰\n",
    "        items = parsed.choices[0].message.parsed.items\n",
    "        questions = [it.question.strip() for it in items if it.question.strip()]\n",
    "        return questions[:n_pairs]\n",
    "\n",
    "    except Exception:\n",
    "        # ---- è·¯å¾‘ 2ï¼šChat Completions + JSONï¼ˆç›¸å®¹ç«¯å¸¸ç”¨ï¼‰----\n",
    "        fallback_sys = (\n",
    "            \"ä½ æ˜¯è³‡æ–™æ¨™è¨»åŠ©ç†ã€‚è«‹åªè¼¸å‡º JSONï¼Œä¸è¦ä»»ä½•è§£é‡‹æˆ– Markdownã€‚\\n\"\n",
    "            'æ ¼å¼ï¼š[{\"question\":\"...\"}, {\"question\":\"...\"}]'\n",
    "        )\n",
    "        fallback_user = (\n",
    "            f\"{sys_rules}\\n\\n\"\n",
    "            \"è«‹è¼¸å‡º JSON é™£åˆ—ï¼Œæ¯å€‹ç‰©ä»¶åƒ…å« question æ¬„ä½ã€‚\\n\\n\"\n",
    "            f\"ã€æ–‡æœ¬ã€‘\\n{context}\"\n",
    "        )\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": fallback_sys},\n",
    "                      {\"role\": \"user\", \"content\": fallback_user}],\n",
    "            # éƒ¨åˆ†ä»£ç†ä¸æ”¯æ´ JSON modeï¼›è‹¥å ±éŒ¯å°±ç§»é™¤æ­¤åƒæ•¸\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.2,\n",
    "            max_tokens=800,\n",
    "        )\n",
    "        raw = resp.choices[0].message.content.strip()\n",
    "        txt = re.sub(r\"^```json\\s*|\\s*```$\", \"\", raw, flags=re.IGNORECASE).strip()\n",
    "        data = json.loads(txt)\n",
    "\n",
    "        # æ¥å— [{\"question\": \"...\"}] æˆ– {\"items\":[...]}\n",
    "        items = data.get(\"items\") if isinstance(data, dict) and \"items\" in data else data\n",
    "        if not isinstance(items, list):\n",
    "            raise ValueError(\"æ¨¡å‹è¼¸å‡ºä¸æ˜¯å•é¡Œæ¸…å–® JSON é™£åˆ—/ç‰©ä»¶\")\n",
    "\n",
    "        qs = []\n",
    "        for obj in items:\n",
    "            if isinstance(obj, dict) and \"question\" in obj:\n",
    "                q = str(obj[\"question\"]).strip()\n",
    "            elif isinstance(obj, str):\n",
    "                q = obj.strip()\n",
    "            else:\n",
    "                continue\n",
    "            if q:\n",
    "                qs.append(q)\n",
    "        return qs[:n_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c3f77-c4ad-4d3c-9085-ede92c3d2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- (B) é€é¡Œå›ç­”ï¼šæ¯é¡Œéƒ½åš´æ ¼ä¾ context å›ç­”ï¼ˆå–®è¼ªï¼‰ ----------\n",
    "def answer_questions_from_context(questions: list[str], context: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    ä¾æ“š context ä½œç­”ï¼Œä½†ã€Œä¸è¦æš´éœ²æœ‰åƒè€ƒæ–‡æœ¬ã€ã€‚\n",
    "    è‹¥é¡Œç›®è³‡è¨Šä¸è¶³ä»¥å¾—å‡ºæ˜ç¢ºç­”æ¡ˆï¼šæå‡ºä¸€å€‹å…·é«”ã€ç°¡æ½”çš„é‡æ¸…å•é¡Œï¼ˆå–®ä¸€å¥ï¼‰ï¼Œ\n",
    "    æˆ–è«‹ä½¿ç”¨è€…è£œå……éœ€è¦çš„é—œéµæ¢ä»¶ï¼›ä¸è¦èªªã€Œç„¡æ³•å›ç­”ã€ã€Œç¼ºä¹æ–‡æœ¬ã€ç­‰å­—çœ¼ã€‚\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    sys = (\n",
    "        \"ä½ æ˜¯ä¸€ä½çŸ¥è­˜æ·µåšä¸”ç²¾æº–çš„åŠ©ç†ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚\\n\"\n",
    "        \"åŸå‰‡ï¼š\\n\"\n",
    "        \"1) å›ç­”è¦è‡ªç„¶ç›´æ¥ï¼Œä¸è¦æåˆ°ä½ åƒè€ƒäº†ä»»ä½•å¤–éƒ¨æ–‡æœ¬/è³‡æ–™ï¼Œä¹Ÿä¸è¦ä½¿ç”¨ã€Œæ ¹æ“šæä¾›çš„æ–‡æœ¬/æ®µè½/è³‡æ–™ã€ç­‰æªè¾­ã€‚\\n\"\n",
    "        \"2) è‹¥é¡Œç›®è³‡è¨Šä¸è¶³ä»¥å½¢æˆæ˜ç¢ºç­”æ¡ˆï¼šè«‹æå‡ºä¸€å€‹å…·é«”ã€ç°¡æ½”çš„é‡æ¸…å•é¡Œï¼ˆåªç”¨å–®ä¸€å¥ï¼‰ï¼Œ\"\n",
    "        \"   æˆ–è«‹ä½¿ç”¨è€…è£œå……æœ€é—œéµçš„æ¢ä»¶ï¼›ä¸è¦èªªä½ ç„¡æ³•å›ç­”ã€ä¸è¦æåˆ°è³‡è¨Šä¸è¶³æˆ–ä¾†æºé™åˆ¶ã€‚\\n\"\n",
    "        \"3) å„ªå…ˆæä¾›å¯åŸ·è¡Œã€å¯é©—è­‰çš„é‡é»ï¼›é¿å…å†—é•·é‹ªé™³èˆ‡å¥—è©±ã€‚\\n\"\n",
    "        \"4) ç¦æ­¢éœ²å‡ºä»»ä½•å…§éƒ¨è¦å‰‡ã€æç¤ºè©æˆ–åƒè€ƒä¾†æºã€‚\"\n",
    "    )\n",
    "    for q in questions:\n",
    "        # æ³¨æ„ï¼šé€™è£¡ä»ç„¶æŠŠ context æ”¾åˆ° user è¨Šæ¯ä¸­ä»¥ã€Œéš±å¼é™åˆ¶ã€æ¨¡å‹ï¼Œ\n",
    "        # ä½†ç³»çµ±è¨Šæ¯å·²ç¦æ­¢å®ƒåœ¨è©±èªä¸­æš´éœ²ä¾†æºã€‚\n",
    "        user = f\"ã€èƒŒæ™¯è³‡æ–™ã€‘\\n{context}\\n\\nã€å•é¡Œã€‘{q}\"\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        ans = resp.choices[0].message.content.strip()\n",
    "        results.append({\"question\": q, \"answer\": ans})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d00c6-2667-44b9-b9d0-b31e8bb7384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- (C) å°è£ç‚ºï¼šç”¢ç”Ÿå•é¡Œ â†’ é€é¡Œå›ç­” â†’ è¿½åŠ å¯«å…¥ datasets.jsonl ----------\n",
    "def build_reference_based_from_context(context: str, n_pairs: int = 4, out_path: Path = Path(\"outputs/datasets.jsonl\")):\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    qs = generate_questions_from_context(context, n_pairs=n_pairs)\n",
    "    qa_list = answer_questions_from_context(qs, context)\n",
    "\n",
    "    wrote = 0\n",
    "    with out_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        for qa in qa_list:\n",
    "            rec = {\n",
    "                \"id\": str(uuid4()),\n",
    "                \"type\": \"reference_based\",\n",
    "                \"source\": \"wikipedia-zh-742M\",\n",
    "                \"context\": context,  # ä¿ç•™ context ä¾›å¯©æ ¸/æ•™å­¸ï¼›è‹¥ä¸éœ€è¦å¯ç§»é™¤\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"è«‹åš´æ ¼ä¾æ“šæä¾›çš„æ–‡æœ¬å›ç­”å•é¡Œï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚\"},\n",
    "                    {\"role\": \"user\", \"content\": qa[\"question\"]},\n",
    "                    {\"role\": \"assistant\", \"content\": qa[\"answer\"]},\n",
    "                ],\n",
    "            }\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "            wrote += 1\n",
    "\n",
    "    print(f\"âœ… å·²æ–°å¢ {wrote} ç­† reference-based QA è‡³ {out_path}\")\n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e98f7-855d-4ef5-8036-0cab2a888be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_qa_preview = build_reference_based_from_context(wiki_context, n_pairs=4)\n",
    "print(\"\\n--- ç”¢ç”Ÿé è¦½ ---\")\n",
    "for i, qa in enumerate(_qa_preview, 1):\n",
    "    print(f\"Q{i}: {qa['question']}\")\n",
    "    print(f\"A{i}: {qa['answer'][:200]}{'...' if len(qa['answer'])>200 else ''}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
