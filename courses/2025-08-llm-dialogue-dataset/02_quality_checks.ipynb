{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3014b7ac-7748-46f6-965e-8f92b57377cf",
   "metadata": {},
   "source": [
    "# 02 - è³‡æ–™å“è³ªæª¢æŸ¥èˆ‡éæ¿¾ï¼ˆQuality Checksï¼‰\n",
    "\n",
    "<div align=\"left\" style=\"line-height: 1;\">\n",
    "  <a href=\"https://discord.gg/Cx737yw4ed\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-Twinkle%20AI-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "  <a href=\"https://huggingface.co/twinkle-ai\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Twinkle%20AI-ffc107?color=ffc107&logoColor=white\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "      <a href=\"https://colab.research.google.com/github/ai-twinkle/llm-lab/blob/main/courses/2025-08-llm-dialogue-dataset/02_quality_checks.ipynb\" target=\"_blank\" style=\"margin: 2px;\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open 02_quality_checks In Colab\" style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "  </a>\n",
    "</div>\n",
    "\n",
    "ç›®æ¨™ï¼š\n",
    "- è¼‰å…¥ `raw.jsonl`\n",
    "- è¦å‰‡å¼æª¢æŸ¥ï¼šæ•æ„Ÿè© / çµæ§‹å®Œæ•´ / é•·åº¦é–€æª» / ä¸å« placeholder\n",
    "- ç”¢å‡º `clean.jsonl`\n",
    "- ç”Ÿæˆæ‘˜è¦å ±è¡¨ï¼ˆé€šé/å‰”é™¤çµ±è¨ˆã€å‰”é™¤åŸå› åˆ†ä½ˆï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8ced3-2e81-4f19-af3f-99c98c5efbd8",
   "metadata": {},
   "source": [
    "### è¨»ï¼šä¸è«–å¦‚ä½•ï¼Œç¦ç”¨ [opencc-python](https://github.com/yichen0831/opencc-python) åšä»»ä½•è½‰æ›\n",
    "\n",
    "é›–ç„¶ OpenCC çš„ç°¡è½‰ç¹åŠŸèƒ½å¾ˆæ–¹ä¾¿ï¼Œä½†å®ƒåªæ˜¯æ©Ÿæ¢°å¼è½‰æ›ï¼Œç¹é«”å­—æœ‰æ™‚æœƒè¢«èª¤åˆ¤æˆ–éŒ¯è½‰ï¼Œå°è‡´èªæ„éŒ¯èª¤æˆ–ä¸ç¬¦åˆåœ¨åœ°ç”¨æ³•ï¼Œå› æ­¤ä¸¦ä¸é©åˆéœ€è¦ç²¾æº–ç¹é«”è¼¸å‡ºçš„æƒ…å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed0c38-dc62-44ef-aa93-dc043781f5c8",
   "metadata": {},
   "source": [
    "## 1. æº–å‚™è·¯å¾‘èˆ‡ä¾è³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e97990-9f6d-4134-b1d0-4e7966210732",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p outputs\n",
    "!curl -L \"https://raw.githubusercontent.com/ai-twinkle/llm-lab/main/courses/2025-08-llm-dialogue-dataset/outputs/datasets.jsonl\" \\\n",
    "  -o outputs/datasets.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2e6e0-336f-4893-88b9-2b88dc67c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, re, statistics\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "INPUT_PATH = Path(\"outputs/datasets.jsonl\")\n",
    "OUTPUT_DIR = Path(\"outputs\")\n",
    "OUTPUT_CLEAN = OUTPUT_DIR / \"clean.jsonl\"\n",
    "OUTPUT_REPORT = OUTPUT_DIR / \"qc_report.json\"\n",
    "\n",
    "assert INPUT_PATH.exists(), f\"æ‰¾ä¸åˆ° {INPUT_PATH}ï¼Œè«‹å…ˆå®Œæˆ 01_generate_dialogs.ipynb\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… è®€å–ä¾†æºï¼š\", INPUT_PATH)\n",
    "print(\"âœ… ä¹¾æ·¨è¼¸å‡ºï¼š\", OUTPUT_CLEAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926d664-eddd-4303-9207-b3a2260afaf3",
   "metadata": {},
   "source": [
    "## 2. è¼‰å…¥è³‡æ–™\n",
    "\n",
    "é€è¡Œè®€å– JSONLï¼Œå­˜åˆ° listã€‚é€™è£¡ä¸åšä»»ä½•è®Šå½¢ï¼Œåªæª¢è¦–åŸºæœ¬éµå€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26301db-4c15-4580-a84b-5f6a4687685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "with INPUT_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            records.append(json.loads(line))\n",
    "        except Exception as e:\n",
    "            # è‹¥å‡ºç¾ç„¡æ³•è§£æçš„è¡Œï¼Œè¨˜éŒ„ä¸¦è·³é\n",
    "            print(\"âš ï¸ ç„¡æ³•è§£æçš„è¡Œï¼Œå·²ç•¥éï¼š\", e)\n",
    "\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9753e1-25c2-4fce-9faa-c6266f19f43c",
   "metadata": {},
   "source": [
    "## 3. å“è³ªè¦å‰‡å®šç¾©\n",
    "\n",
    "æœ¬èª²æ¡ã€Œè¦å‰‡å¼ï¼ˆrule-basedï¼‰ã€æª¢æŸ¥ä»¥å¿«é€Ÿéæ¿¾ï¼š\n",
    "1. **çµæ§‹**ï¼š`messages` è‡³å°‘åŒ…å« `system`ã€`user`ã€`assistant` ä¸‰å‰‡ï¼›ä¸”å°è©±æ–‡æœ¬ä¸ç‚ºç©ºã€‚\n",
    "2. **å¤šè¼ªæ€§**ï¼šå°è©±éœ€åŒ…å«è‡³å°‘ 3 è¼ªï¼ˆå¯é¬†ç¶ç‚º 1 è¼ªä»¥ä¸Šï¼Œä½†æœ¬èª²å…ˆæ¡è‡³å°‘ 3 è¼ªï¼‰ã€‚\n",
    "3. **é•·åº¦**ï¼šåˆä½µæ–‡æœ¬é•·åº¦è‡³å°‘ 80 å­—ï¼ˆé¿å…éçŸ­ï¼‰ã€‚\n",
    "4. **æ•æ„Ÿè©**ï¼šéæ¿¾å€‹è³‡æˆ–æ•æ„Ÿè©ï¼ˆç¤ºä¾‹é»‘åå–®ï¼‰ã€‚\n",
    "5. **Placeholder**ï¼šä¸å¾—åŒ…å« `XXX`ã€`<å¡«å……>` é¡ä½”ä½ç¬¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0923e3-6fa0-41bb-97a4-653a036c72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) çµæ§‹/è§’è‰²æª¢æŸ¥\n",
    "def has_min_roles(msgs):\n",
    "    roles = [m.get(\"role\") for m in msgs]\n",
    "    return {\"system\", \"user\", \"assistant\"}.issubset(set(roles))\n",
    "\n",
    "# 2) å¤šè¼ªæ€§ï¼ˆé€™è£¡ä»¥è¨Šæ¯æ•¸ >= 3 è¦–ç‚ºæœ€ä½é–€æª»ï¼›è‹¥éœ€è¦æ›´åš´è¬¹å¯è§£æå›åˆï¼‰\n",
    "def has_min_turns(msgs, min_msgs=3):\n",
    "    return len(msgs) >= min_msgs\n",
    "\n",
    "# 3) é•·åº¦é–€æª»\n",
    "def meet_min_length(msgs, min_chars=80):\n",
    "    total = sum(len((m.get(\"content\") or \"\").strip()) for m in msgs)\n",
    "    return total >= min_chars\n",
    "\n",
    "# 4) æ•æ„Ÿè©ï¼ˆç¤ºä¾‹ï¼‰ï¼šèº«åˆ†è­‰/é›»è©±/åœ°å€/Email/ä¿¡ç”¨å¡/ç”Ÿæ—¥\n",
    "SENSITIVE_PATTERNS = [\n",
    "    r\"\\b[A-Z][12]\\d{8}\\b\",                         # å°ç£èº«åˆ†è­‰æ ¼å¼\n",
    "    r\"\\b09\\d{8}\\b|\\b0\\d{1,2}-\\d{6,8}\\b\",          # æ‰‹æ©Ÿæˆ–å¸‚è©±\n",
    "    r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\",  # email\n",
    "    r\"\\b\\d{4}[- ]?\\d{4}[- ]?\\d{4}[- ]?\\d{4}\\b\",   # ä¿¡ç”¨å¡ 16 ç¢¼\n",
    "    r\"\\b(19|20)\\d{2}[/-]\\d{1,2}[/-]\\d{1,2}\\b\",    # è¥¿å…ƒç”Ÿæ—¥ yyyy/mm/dd æˆ– yyyy-mm-dd\n",
    "]\n",
    "\n",
    "def has_sensitive(text):\n",
    "    return any(re.search(p, text) for p in SENSITIVE_PATTERNS)\n",
    "\n",
    "# 5) Placeholder éæ¿¾\n",
    "PLACEHOLDER_PATTERNS = [r\"XXX\", r\"<å¡«å……>\", r\"\\[PLACEHOLDER\\]\"]\n",
    "\n",
    "def has_placeholder(text):\n",
    "    return any(re.search(p, text, flags=re.IGNORECASE) for p in PLACEHOLDER_PATTERNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5a6cd-4b31-451f-a1c8-c34437a11560",
   "metadata": {},
   "source": [
    "## 4. å–®ç­†æª¢æŸ¥èˆ‡åŸå› æ¨™è¨»\n",
    "\n",
    "è¼¸å…¥ä¸€ç­†è¨˜éŒ„ï¼Œå›å‚³ (æ˜¯å¦é€šé, å‰”é™¤åŸå› é›†åˆ)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495390d6-59f4-4ec5-a7e7-1b236a5a1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_text_by_roles(msgs, roles=(\"assistant\",)):\n",
    "    return \"\\n\".join((m.get(\"content\") or \"\").strip()\n",
    "                     for m in msgs if m.get(\"role\") in roles)\n",
    "\n",
    "def quality_check(record):\n",
    "    reasons = []\n",
    "\n",
    "    msgs = record.get(\"messages\", [])\n",
    "    if not isinstance(msgs, list) or not msgs:\n",
    "        return False, {\"bad_structure\"}\n",
    "\n",
    "    if not has_min_roles(msgs):\n",
    "        reasons.append(\"missing_roles\")\n",
    "\n",
    "    if not has_min_turns(msgs, min_msgs=3):\n",
    "        reasons.append(\"too_few_messages\")\n",
    "\n",
    "    # â¬‡ï¸ åªçœ‹ assistant æ–‡å­—ï¼Œé¿å…æƒåˆ° user æç¤ºå…§çš„ã€Œä¾‹å¦‚ èº«åˆ†è­‰/é›»è©±â€¦ã€\n",
    "    text = join_text_by_roles(msgs, roles=(\"assistant\",))\n",
    "\n",
    "    if not meet_min_length(msgs, min_chars=80):\n",
    "        reasons.append(\"too_short\")\n",
    "\n",
    "    if has_sensitive(text):\n",
    "        reasons.append(\"sensitive_content\")\n",
    "\n",
    "    if has_placeholder(text):\n",
    "        reasons.append(\"placeholder_found\")\n",
    "\n",
    "    return (len(reasons) == 0), set(reasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943576f6-5c01-488e-8e71-f305afae9dd1",
   "metadata": {},
   "source": [
    "## 5. åŸ·è¡Œéæ¿¾ä¸¦è¼¸å‡º `clean.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2ae66-e807-4ecd-a4bf-577825c339d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept, dropped = [], []\n",
    "for rec in records:\n",
    "    ok, reasons = quality_check(rec)\n",
    "    if ok:\n",
    "        kept.append(rec)\n",
    "    else:\n",
    "        dropped.append((rec.get(\"id\"), reasons))\n",
    "\n",
    "with OUTPUT_CLEAN.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for r in kept:\n",
    "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… é€šéï¼š{len(kept)}  ç­†\")\n",
    "print(f\"âŒ å‰”é™¤ï¼š{len(dropped)} ç­†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec9a4-9eea-4a5a-8af4-0cdbead0a49a",
   "metadata": {},
   "source": [
    "## 6. ç”¢å‡ºå“è³ªå ±è¡¨\n",
    "\n",
    "çµ±è¨ˆå‰”é™¤åŸå› åˆ†ä½ˆã€é•·åº¦åˆ†ä½ˆï¼ˆé€šéè€…ï¼‰ï¼Œä¸¦è¼¸å‡º `qc_report.json` æ–¹ä¾¿ä¿å­˜èˆ‡è¿½è¹¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91348e15-d898-4b96-a6f4-8e19fa1080ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰”é™¤åŸå› åˆ†ä½ˆ\n",
    "reason_counter = Counter()\n",
    "for _id, reasons in dropped:\n",
    "    reason_counter.update(reasons)\n",
    "\n",
    "# é€šéè³‡æ–™é•·åº¦ï¼ˆå­—å…ƒè¨ˆï¼‰åˆ†ä½ˆ\n",
    "lengths = []\n",
    "for r in kept:\n",
    "    lengths.append(sum(len((m.get(\"content\") or \"\").strip()) for m in r[\"messages\"]))\n",
    "\n",
    "report = {\n",
    "    \"input_total\": len(records),\n",
    "    \"kept\": len(kept),\n",
    "    \"dropped\": len(dropped),\n",
    "    \"drop_reasons\": dict(reason_counter),\n",
    "    \"length_stats_kept\": {\n",
    "        \"min\": min(lengths) if lengths else 0,\n",
    "        \"max\": max(lengths) if lengths else 0,\n",
    "        \"mean\": round(statistics.mean(lengths), 2) if lengths else 0,\n",
    "        \"median\": statistics.median(lengths) if lengths else 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "with OUTPUT_REPORT.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(report, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(json.dumps(report, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb83d71-8c3f-41d6-adb7-3ff00e181cfb",
   "metadata": {},
   "source": [
    "## 7. æŠ½æ¨£æª¢è¦–é€šéæ¨£æœ¬ï¼ˆå‰ 2 ç­†ï¼‰\n",
    "\n",
    "ç¢ºèªæ¸…æ´—å¾Œçš„è³‡æ–™çµæ§‹èˆ‡å…§å®¹æ˜¯å¦ç¬¦åˆé æœŸã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78a29c-74fa-465c-a16d-1ba8f406406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview = []\n",
    "with OUTPUT_CLEAN.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 2:\n",
    "            break\n",
    "        preview.append(json.loads(line))\n",
    "\n",
    "for i, s in enumerate(preview, 1):\n",
    "    print(f\"\\n--- Clean Sample {i} / topic={s.get('topic')} ---\")\n",
    "    text = s[\"messages\"][-1][\"content\"]\n",
    "    print(text[:500] + (\"...\" if len(text) > 500 else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebdc34-7526-4679-bf09-b9f868311a92",
   "metadata": {},
   "source": [
    "## 8.ï¼ˆå¯é¸ï¼‰LLM è¼”åŠ©æª¢æŸ¥ï¼ˆå¯¦å‹™å»ºè­°ï¼‰\n",
    "> æ‰€è¬‚çš„ LLM-as-Judge\n",
    "\n",
    "åœ¨è¦å‰‡å¼æª¢æŸ¥å¾Œï¼Œå¯æŠ½æ¨£ä½¿ç”¨ LLM ä¾†åšèªç¾©å±¤é¢çš„æª¢æŸ¥ï¼ˆå¦‚ï¼šæ˜¯å¦ç¬¦åˆä¸»é¡Œã€èªæ°£ã€æ˜¯å¦å«å±éšªå»ºè­°ç­‰ï¼‰ã€‚  \n",
    "ä»¥ä¸‹ç‚ºç¤ºæ„ç¨‹å¼ï¼ˆé è¨­è¨»è§£ï¼Œä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8958b-6f3a-4417-9ba2-e13a4a5500fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# API_KEY = \"\"  # è¨»è§£ï¼šé€™è£¡è¦å• Twinkle AI ç¤¾ç¾¤\n",
    "# BASE_URL = \"https://litellm-ekkks8gsocw.dgx-coolify.apmic.ai\"\n",
    "# client = OpenAI(api_key=API_KEY, base_url=f\"{BASE_URL}/v1\")\n",
    "#\n",
    "# def llm_qc_judgement(text: str) -> bool:\n",
    "#     \"\"\"å›å‚³ True è¦–ç‚ºé€šéï¼›False è¦–ç‚ºä¸é€šé\"\"\"\n",
    "#     prompt = f\"è«‹é–±è®€ä»¥ä¸‹å°è©±æ˜¯å¦ç¬¦åˆï¼šä¸»é¡Œé€£è²«ã€èªæ°£æ­£å¼å‹å–„ã€ç„¡æ•æ„Ÿè³‡æ–™ã€ç„¡å±éšªå»ºè­°ã€‚\\n\\n{text}\\n\\nè«‹åªå›ç­”ï¼šPASS æˆ– FAILã€‚\"\n",
    "#     resp = client.chat.completions.create(\n",
    "#         model=\"gemma-3-12b-it\",\n",
    "#         messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "#         temperature=0.0,\n",
    "#         max_tokens=10,\n",
    "#     )\n",
    "#     ans = resp.choices[0].message.content.strip().upper()\n",
    "#     return ans.startswith(\"PASS\")\n",
    "#\n",
    "# # ç¤ºä¾‹ï¼ˆåªæª¢æŸ¥å‰ 3 ç­†ï¼‰\n",
    "# for s in preview:\n",
    "#     ok = llm_qc_judgement(\"\\n\".join(m[\"content\"] for m in s[\"messages\"]))\n",
    "#     print(\"LLM QC ->\", \"PASS\" if ok else \"FAIL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfbf3a-5157-4bab-826b-64c510619a31",
   "metadata": {},
   "source": [
    "## 9.ï¼ˆå¯é¸ï¼‰å¦‚æœç”Ÿæˆè³‡æ–™é›†ä¸€ç›´æ²’é€šé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d49ad4-a02e-4416-81a3-22bdd0b10ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Debugï¼šé€ç­†åˆ—å‡ºå‘½ä¸­çš„æ•æ„Ÿè© / Placeholderï¼ˆå«å‰å¾Œæ–‡ï¼‰\n",
    "import re\n",
    "\n",
    "def _ctx(text: str, start: int, end: int, width: int = 50) -> str:\n",
    "    s = max(0, start - width)\n",
    "    e = min(len(text), end + width)\n",
    "    return text[s:start] + \"ã€\" + text[start:end] + \"ã€‘\" + text[end:e]\n",
    "\n",
    "def debug_scan_record(rec: dict, show_only_hits: bool = True):\n",
    "    rid = rec.get(\"id\", \"<no-id>\")\n",
    "    topic = rec.get(\"topic\", \"\")\n",
    "    msgs = rec.get(\"messages\", [])\n",
    "\n",
    "    # ğŸ”‘ åªæƒ assistantï¼ˆæ¨¡å‹è¼¸å‡ºï¼‰\n",
    "    text = \"\\n\".join((m.get(\"content\") or \"\") for m in msgs if m.get(\"role\") == \"assistant\")\n",
    "\n",
    "    sens_hits = []\n",
    "    for p in SENSITIVE_PATTERNS:\n",
    "        for m in re.finditer(p, text, flags=re.IGNORECASE):\n",
    "            sens_hits.append((p, m.start(), m.end(), m.group(0)))\n",
    "\n",
    "    ph_hits = []\n",
    "    for p in PLACEHOLDER_PATTERNS:\n",
    "        for m in re.finditer(p, text, flags=re.IGNORECASE):\n",
    "            ph_hits.append((p, m.start(), m.end(), m.group(0)))\n",
    "\n",
    "    if sens_hits or ph_hits or not show_only_hits:\n",
    "        print(f\"\\n=== Record id={rid} | topic={topic} ===\")\n",
    "        if sens_hits:\n",
    "            print(f\"Sensitive matches ({len(sens_hits)}):\")\n",
    "            for p, s, e, g in sens_hits:\n",
    "                print(f\" - pattern: {p}  | match: {g!r}\")\n",
    "                print(\"   ...\", _ctx(text, s, e), \"...\")\n",
    "        if ph_hits:\n",
    "            print(f\"Placeholder matches ({len(ph_hits)}):\")\n",
    "            for p, s, e, g in ph_hits:\n",
    "                print(f\" - pattern: {p}  | match: {g!r}\")\n",
    "                print(\"   ...\", _ctx(text, s, e), \"...\")\n",
    "    return bool(sens_hits), bool(ph_hits)\n",
    "\n",
    "def debug_scan_all(recs: list[dict], limit: int | None = None):\n",
    "    n = 0\n",
    "    total_sens = total_ph = 0\n",
    "    for rec in recs:\n",
    "        sens, ph = debug_scan_record(rec)\n",
    "        total_sens += int(sens)\n",
    "        total_ph += int(ph)\n",
    "        n += 1\n",
    "        if limit and n >= limit:\n",
    "            break\n",
    "    print(f\"\\nSummary: scanned {n} records | with_sensitive={total_sens} | with_placeholder={total_ph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4161db3-b9e8-430e-b8b7-a5492edc3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡è¨­ä½ å·²åœ¨å‰é¢è¼‰å…¥ records = [...]ï¼ˆå¾ raw.jsonlï¼‰\n",
    "debug_scan_all(records)          # æƒå…¨éƒ¨\n",
    "# æˆ–åªçœ‹å‰ 10 ç­†\n",
    "# debug_scan_all(records, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ca216-0dd5-4c8e-8e23-e7a05a3559e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
